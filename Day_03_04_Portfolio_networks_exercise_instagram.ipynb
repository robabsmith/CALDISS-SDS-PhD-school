{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 03 - 04 - Portfolio - networks_exercise_instagram.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robabsmith/CALDISS-SDS-PhD-school/blob/master/Day_03_04_Portfolio_networks_exercise_instagram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L53IOJPRDgf",
        "colab_type": "text"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQfgQ9a5QfTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STandard stuff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import itertools # Python's amazing iteration & combination library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvZdilOdQ11B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For visualization\n",
        "!pip install -U bokeh\n",
        "!pip install -q holoviews\n",
        "\n",
        "# Import the libraries and link to the bokeh backend\n",
        "import holoviews as hv\n",
        "from holoviews import opts\n",
        "hv.extension('bokeh')\n",
        "from bokeh.plotting import show\n",
        "\n",
        "# Setting the default figure size a bit larger\n",
        "defaults = dict(width=750, height=750, padding=0.1,\n",
        "                xaxis=None, yaxis=None)\n",
        "hv.opts.defaults(\n",
        "    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilWBAYXQoUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Stuff\n",
        "import networkx as nx\n",
        "import community # `python-louvain` is implemented here\n",
        "from networkx.algorithms import bipartite # bipartite NW algos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmdoxqxQRKiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Blockmodel Stuff\n",
        "!wget https://github.com/CALDISS-AAU/sdsphd19_coursematerials/raw/master/wednesday_network-blockmodeling/blockmodeling_material.zip # downloading module and data files to googe drive session\n",
        "!unzip 'blockmodeling_material.zip' # unzipping\n",
        "\n",
        "# import the necessary modules\n",
        "import blockmodeling as bm\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sc\n",
        "import scipy.cluster.hierarchy as sch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YtLz6yARvu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# API&Scraping&instagramm\n",
        "!pip3 install instaloader # Installing instaloader\n",
        "import instaloader\n",
        "L = instaloader.Instaloader()\n",
        "\n",
        "import requests as rq # The requests library handles \"requests\" to APIs similar to a browser that requests a webpage given a URL\n",
        "from nltk.tokenize import TweetTokenizer # A bit of a transition into NLP. The tweet tokenizer from the NLTK library will help us extract the hashtags from post-text\n",
        "tknzr = TweetTokenizer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtXZbE0gQdVf",
        "colab_type": "text"
      },
      "source": [
        "# Task\n",
        "\n",
        "So guys, now its time to put it all together. Take the two notebooks by Carl, and Daniel, and Carl, and do the following:\n",
        "\n",
        "1. Extract Instagram Tag infos of your choice\n",
        "2. Generate a bipartite User-Tag network\n",
        "3. Project it on either the user or the tag mode (your choice)\n",
        "4. Apply blockmodeling on it \n",
        "\n",
        "* [Networks general: Daniel](https://colab.research.google.com/github/CALDISS-AAU/sdsphd19_coursematerials/blob/master/notebooks/CALDISS_PHD_Intro_networks.ipynb#&offline=true&sandboxMode=true)\n",
        "* [Blockmodels: Carl](https://colab.research.google.com/github/CALDISS-AAU/sdsphd19_coursematerials/blob/master/wednesday_network-blockmodeling/Lab_Blockmodeling.ipynb#&offline=true&sandboxMode=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJUQB3uASjJ5",
        "colab_type": "text"
      },
      "source": [
        "# Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPBQFVS9SlLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instagram base url preffix\n",
        "tagurl_prefix = 'https://www.instagram.com/explore/tags/'\n",
        "\n",
        "# suffix to append to tag request url to retrieve data in JSON format\n",
        "tagurl_suffix = '/?__a=1'\n",
        "\n",
        "# suffix to end cursor when requesting posts by tag\n",
        "tagurl_endcursor = '&max_id='\n",
        "\n",
        "# a generic media post preffix (concat with media shortcode to view)\n",
        "posturl_prefix = 'https://www.instagram.com/p/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kudm7HruSnet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Find your own instagramm tag to explore!!!!!\n",
        "#\n",
        "tags = ['namaalborg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF91Kcc4StWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# urls to initial tags using the above url-components\n",
        "queries = [ tagurl_prefix + tag + tagurl_suffix for tag in tags ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK6fo1OSTEa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges = []\n",
        "for q in queries:    \n",
        "    for i in range(5): # how many iterations/deepth ?\n",
        "      r = rq.get(q).json()\n",
        "      end_cursor = r['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor']\n",
        "      edges.extend(r['graphql']['hashtag']['edge_hashtag_to_media']['edges'])\n",
        "      print(i)\n",
        "      q = q + tagurl_endcursor + end_cursor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjxRqCz0TH-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_dicts = [] #empty list\n",
        "\n",
        "for post in edges: #iterate all raw posts\n",
        "\n",
        "  if post['node']['edge_media_to_caption']['edges'] == []: # hop to the next if no text in the post\n",
        "    continue\n",
        "    \n",
        "  post_dict = {} # empty dictionary\n",
        "  id_owner = post['node']['owner']['id'] # pick out user-id\n",
        "  shortcode = post['node']['shortcode'] # pick out short post identifier\n",
        "  text = post['node']['edge_media_to_caption']['edges'][0]['node']['text'] # pick out post text\n",
        "  \n",
        "  # Pick hashtags from text\n",
        "  tokens = tknzr.tokenize(text)\n",
        "  tags = [x.strip('#') for x in tokens if x.startswith('#')]\n",
        "\n",
        "  # fill in dictionary with values\n",
        "  post_dict['id_owner'] = id_owner\n",
        "  post_dict['shortcode'] = shortcode\n",
        "  post_dict['tags'] = tags\n",
        "  post_dict['text'] = text\n",
        "\n",
        "  post_dicts.append(post_dict) #append the dictionary to a list of post-dictionaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JKaWfzFTNMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create DF\n",
        "posts_df = pd.DataFrame(post_dicts)\n",
        "\n",
        "# Remove hashtags that are not a hashtag (emptyspace & mistakes)\n",
        "posts_df['tags'] = posts_df['tags'].map(lambda t: [x for x in t if x.isalnum()])\n",
        "\n",
        "# Kick out posts with 0 hashtags\n",
        "posts_df = posts_df[posts_df['tags'].map(len) != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4kqyvYhmyd_",
        "colab_type": "text"
      },
      "source": [
        "## Simple stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JtUU0lpm2GK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# People with most posts\n",
        "posts_df['id_owner'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MR5PK1sm8bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look up who these people are (this line gets us also other information about the user)\n",
        "profile = instaloader.Profile.from_id(L.context, 420900264)\n",
        "# nigerian.pvc.awareness\n",
        "# rinathama.m\n",
        "# henry_expert_trade\n",
        "# inuka_consultant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOqy3qp7nBjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "profile.username"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr0IEYwNTh2Q",
        "colab_type": "text"
      },
      "source": [
        "# Create a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBcRNVdZTri9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new graph\n",
        "B = nx.Graph()\n",
        "# We need to specify the nodes for level 0 - this will be our users\n",
        "B.add_nodes_from(list(set(posts_df.id_owner)), bipartite= 1)\n",
        "# Then we need to add hashtags nodes as level 1 nodes\n",
        "B.add_nodes_from(list(set(itertools.chain(*posts_df.tags))), bipartite= 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjA_UC_4T1u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This quick loop will generate edges between users and hashtags\n",
        "# Every time someone mentions a #hashtag, a link is created\n",
        "\n",
        "bi_edges = []\n",
        "for i in posts_df[['id_owner','tags']].iterrows(): # we do this row-by-row since each row is a post\n",
        "  id_owner = i[1]['id_owner']\n",
        "  for j in i[1]['tags']:\n",
        "    bi_edges.append((id_owner, j)) # edges are appended to a list as a tuple (id_owner, hashtag)\n",
        "\n",
        "# Let's add the edges to our graph\n",
        "B.add_edges_from(bi_edges)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IuIHgCiUIv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract a set of nodes with level 0\n",
        "top_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
        "\n",
        "# the remaining nodes are then level 1\n",
        "bottom_nodes = set(B) - top_nodes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaSxzFs8nr3M",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Graph\n",
        "\n",
        "It can be a good idea to filter the Graph before analysing. For instance, we can remove all hashtags with low degree-centrality. This can be interpreted as - kicking out made up hashtags or extremely underused ones. We will calculate a percentile threshold and exclude everything under it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blJ6C4AvpGv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating degree centrality for the Graph\n",
        "degree_centrality = nx.degree_centrality(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAlIKUr3of_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting a \"reasonable\" lower bound.\n",
        "perc_filter = np.percentile([v for u,v in degree_centrality.items()], 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au-USbGFpc9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a subgraph based on nodes with a degree_centrality over the threshold\n",
        "nodes_selected = [x for x,y in degree_centrality.items() if y >= perc_filter]\n",
        "\n",
        "B = B.subgraph(nodes_selected)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooXLo_41phk_",
        "colab_type": "text"
      },
      "source": [
        "## Analysing the Graph\n",
        "\n",
        "Now we are going to calculate some network indicators and once done, we will export a DataFrame analyse them further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xwd4O-cppH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recalculate degre-centrality and assign it as a node-attribute\n",
        "degree_centrality = nx.degree_centrality(B)\n",
        "nx.set_node_attributes(B, degree_centrality, 'degree')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MkEa6JTp5R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same for Eigenvector Centrality\n",
        "eigenvector = nx.eigenvector_centrality(B)\n",
        "nx.set_node_attributes(B, eigenvector, 'eigenvector_centrality')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpoDGJWVp9JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same for community detection\n",
        "communities = community.best_partition(B, resolution = 1)\n",
        "nx.set_node_attributes(B, communities, 'community')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP40ZvkKqKjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_df = pd.DataFrame(dict(B.nodes(data=True))).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAv4aUqlqOfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_df['community'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySIF9zuJqXaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the 5 most popular hashtags for each identified community\n",
        "tag_per_com = graph_df.groupby('community')['degree'].nlargest(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqef7qUlUNq0",
        "colab_type": "text"
      },
      "source": [
        "# Assign the plot to an object and save the visual output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLTpjWm2URGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's project this graph using a weighted projection\n",
        "G_proj = bipartite.weighted_projected_graph(B, top_nodes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqA4Lqe2WlPh",
        "colab_type": "text"
      },
      "source": [
        "Saving the file is simple, and can be processed in GEPHI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH0LM2pcW2ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nx.write_gexf(G_proj, 'nam.gexf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aclY_cK9WFms",
        "colab_type": "text"
      },
      "source": [
        "Now lets do some blogmodelling :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVivi2JiYdxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to matrix (numpy.matrix)\n",
        "mat=nx.adjacency_matrix(B).todense()\n",
        "\n",
        "# Extract the node labels into a list - useful later on\n",
        "nodelabels=list(B.nodes())\n",
        "\n",
        "# Display the sociomatrix\n",
        "bm.displaySociomatrix(mat,nodelabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1PQxqHPWYnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the network (you might get a warning message the first time - then do it again)\n",
        "nx.draw(B,with_labels=True,node_color='#FFA0A0', node_size=500)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTYIzURG-MR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate indirect structural equivalence (Hamming distances)\n",
        "dist=bm.indirectSEhamming(posts_df) # Also works with bm.indirectSE(mat,method='hamming')\n",
        "\n",
        "# or calculate correlation-based indirect structural equivalence instead\n",
        "#corr=bm.indirectSEcorr(mat) # Also works with bm.indirectSE(mat,method='corr')\n",
        "# As the clustering functionality here works for distances, we need to then convert correlations to distances\n",
        "# I have added a function for this: corr2dist(mat) - so if you do the following:\n",
        "#dist=bm.corr2dist(corr)\n",
        "# ...you should have something that will work as we continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ICXXQj-MR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the distance matrix if you want\n",
        "print(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emvJ_UIt-MR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to do hierarchical clustering on these distance values, this must first be converted to a condensed distance matrix\n",
        "# For this, we use scipy.spatial.distance.squareform:\n",
        "\n",
        "dist_cond = sc.spatial.distance.squareform(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3HDQEcs-MR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When doing (agglomerative/bottom-up) hierarchical clustering, we can use one out of many different methods for clustering\n",
        "# 'single-link' is typically NOT recommended; 'complete', 'average' and 'ward' are more common in this context\n",
        "\n",
        "# Using the (non-weighted) average clustering approach, we create our clustering object\n",
        "Z=sch.linkage(dist_cond, method='complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "M1yyFaRe-MSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then we can plot the dendrogram for this particular hierarchical clustering\n",
        "plt.figure(figsize=(10, 7))\n",
        "sch.dendrogram(Z,labels=nodelabels) # ...using the nodelabels we extracted in the beginning\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmcJ_qhc-MSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dendrogram should assist us in choosing a suitable cutoff in the dendrogram\n",
        "# This cutoff will thus specify the number of positions our blockmodel will have,\n",
        "# and which nodes/actors that will be part of different partitions\n",
        "\n",
        "\n",
        "# We use the fcluster function to \"cut\" the dendrogram at a suitable level. First set that threshold/cutoff value:\n",
        "threshold=11\n",
        "\n",
        "partition = sch.fcluster(Z,threshold,'distance')\n",
        "\n",
        "# This 'partition' object is a 1-dimensional array (numpy.ndarray), indicating (for each node) which position it belongs to\n",
        "\n",
        "# Have a look at it:\n",
        "print(partition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXPqALlj-MSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check that you got the number of partitions that you wanted\n",
        "len(np.unique(partition))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYEWHuxF-MSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An alternative (and better) way to store this partition is in the form of a dictionary, of lists\n",
        "# In the blockmodeling library, I have created a function that generates such a dictionary, from your partition list\n",
        "\n",
        "blockdict=bm.createBlockdict(partition)\n",
        "\n",
        "# Display it and you will see\n",
        "bm.displayBlockdict(blockdict,nodelabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOLPgAVK-MSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finally, given your original sociomatrix (max),\n",
        "# the partition you have found (blockdict), and\n",
        "# the nodelabels, you can display the final blockmodel\n",
        "\n",
        "bm.displayBlockmodel(mat,blockdict,nodelabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0hBjTS-MSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To assist in interpreting this, I have created a function for\n",
        "# calculating block densities. It returns a numpy ndarray, containing the\n",
        "# block densities for the partition specified in blockdict\n",
        "# This blockimage is sorted according to the indices of blockdict,\n",
        "# i.e. following the same order as the blockmodel above\n",
        "\n",
        "densityBI=bm.calcDensityBlockimage(mat,blockdict)\n",
        "\n",
        "print(np.around(densityBI,decimals=2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}